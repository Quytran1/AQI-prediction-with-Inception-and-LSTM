{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(\n",
    "            y, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "\n",
    "def create_time_series_dataloader(X, y, batch_size=32, shuffle=True, num_workers=0):\n",
    "    dataset = TimeSeriesDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameters\n",
    "batch_size = 64\n",
    "lr1 = 0.005\n",
    "lr2 = 0.0001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data_train_Hyderabad = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Hyderabad_train.npz\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "train_loader_Hyderabad = create_time_series_dataloader(\n",
    "    data_train_Hyderabad[\"samples\"],\n",
    "    data_train_Hyderabad[\"labels\"],\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_train_Dehli = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Dehli_train.npz\", allow_pickle=True\n",
    ")\n",
    "train_loader_Dehli = create_time_series_dataloader(\n",
    "    data_train_Dehli[\"samples\"],\n",
    "    data_train_Dehli[\"labels\"],\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_train_Bengaluru = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Bengaluru_train.npz\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "train_loader_Bengaluru = create_time_series_dataloader(\n",
    "    data_train_Bengaluru[\"samples\"],\n",
    "    data_train_Bengaluru[\"labels\"],\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_train_Taiwan = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Taiwan_train.npz\", allow_pickle=True\n",
    ")\n",
    "train_loader_Taiwan = create_time_series_dataloader(\n",
    "    data_train_Taiwan[\"samples\"],\n",
    "    data_train_Taiwan[\"labels\"],\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        dim = d_model // 4\n",
    "        self.conv1 = nn.Conv1d(d_model, dim, kernel_size=1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(dim, dim, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(dim, dim, kernel_size=5, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(dim, dim, kernel_size=7, padding=3)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1x1 = nn.Conv1d(d_model, dim, kernel_size=1)\n",
    "        self.bnv1x1 = nn.BatchNorm1d(num_features=dim)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.conv1x1(self.maxpool(x))\n",
    "\n",
    "        branch2 = self.conv1(x)\n",
    "        branch2_1 = self.conv2(branch2)\n",
    "        branch2_2 = self.conv3(branch2)\n",
    "        branch2_3 = self.conv4(branch2)\n",
    "\n",
    "        outputs = torch.cat([branch1, branch2_1, branch2_2, branch2_3], dim=1)\n",
    "        outputs = F.relu(self.bn(outputs))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class InceptionTime(nn.Module):\n",
    "    def __init__(self, k_model, d_model):\n",
    "        super(InceptionTime, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(k_model, d_model, kernel_size=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(d_model)\n",
    "\n",
    "        self.conv_shortcut1 = nn.Conv1d(d_model, d_model, kernel_size=1, padding=0)\n",
    "        self.bn1_shortcut1 = nn.BatchNorm1d(d_model)\n",
    "\n",
    "        self.inception1 = InceptionBlock(d_model)\n",
    "        self.inception2 = InceptionBlock(d_model)\n",
    "        self.inception3 = InceptionBlock(d_model)\n",
    "\n",
    "        self.conv_shortcut2 = nn.Conv1d(d_model, d_model, kernel_size=1, padding=0)\n",
    "        self.bn1_shortcut2 = nn.BatchNorm1d(d_model)\n",
    "\n",
    "        self.inception4 = InceptionBlock(d_model)\n",
    "        self.inception5 = InceptionBlock(d_model)\n",
    "        self.inception6 = InceptionBlock(d_model)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        shortcut = self.bn1_shortcut1(self.conv_shortcut1(x))\n",
    "\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.inception3(x)\n",
    "        x = shortcut + x\n",
    "\n",
    "        shortcut = F.relu(self.bn1_shortcut2(self.conv_shortcut2(x)))\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = shortcut + x\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call model\n",
    "model_Taiwan = InceptionTime(8, 128).to(device)\n",
    "\n",
    "model_Dehli = InceptionTime(8, 128).to(device)\n",
    "\n",
    "model_Bengaluru = InceptionTime(8, 128).to(device)\n",
    "\n",
    "model_Hyderabad = InceptionTime(8, 128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# define criterion\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "\n",
    "optimizer_Dehli = optim.SGD(model_Dehli.parameters(), lr=lr1, momentum=0.9)\n",
    "scheduler_Dehli = lr_scheduler.StepLR(optimizer_Dehli, step_size=50, gamma=0.1)\n",
    "\n",
    "optimizer_Hyderabad = optim.SGD(model_Hyderabad.parameters(), lr=lr1, momentum=0.9)\n",
    "scheduler_Hyderabad = lr_scheduler.StepLR(optimizer_Hyderabad, step_size=50, gamma=0.1)\n",
    "\n",
    "optimizer_Bengaluru = optim.SGD(model_Bengaluru.parameters(), lr=lr1, momentum=0.9)\n",
    "scheduler_Bengaluru = lr_scheduler.StepLR(optimizer_Bengaluru, step_size=50, gamma=0.1)\n",
    "\n",
    "optimizer_Taiwan = optim.SGD(model_Taiwan.parameters(), lr=lr1, momentum=0.9)\n",
    "scheduler_Taiwan = lr_scheduler.StepLR(optimizer_Taiwan, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data_test_Dehli = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Dehli_test.npz\", allow_pickle=True\n",
    ")\n",
    "test_loader_Dehli = create_time_series_dataloader(\n",
    "    data_test_Dehli[\"samples\"], data_test_Dehli[\"labels\"], shuffle=False\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_test_Hyderabad = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Hyderabad_test.npz\", allow_pickle=True\n",
    ")\n",
    "test_loader_Hyderabad = create_time_series_dataloader(\n",
    "    data_test_Hyderabad[\"samples\"], data_test_Hyderabad[\"labels\"], shuffle=False\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_test_Bengaluru = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Bengaluru_test.npz\", allow_pickle=True\n",
    ")\n",
    "test_loader_Bengaluru = create_time_series_dataloader(\n",
    "    data_test_Bengaluru[\"samples\"], data_test_Bengaluru[\"labels\"], shuffle=False\n",
    ")\n",
    "\n",
    "# get data\n",
    "data_test_Taiwan = np.load(\n",
    "    \"/kaggle/input/datasetaqi/Taiwan_test.npz\", allow_pickle=True\n",
    ")\n",
    "test_loader_Taiwan = create_time_series_dataloader(\n",
    "    data_test_Taiwan[\"samples\"], data_test_Taiwan[\"labels\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 596/603 [02:14<00:01,  3.87it/s]"
     ]
    }
   ],
   "source": [
    "# training\n",
    "best_loss_Dehli = float(\"inf\")\n",
    "training_loss_Dehli = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss_Dehli = 0.0\n",
    "    for i_Dehli, data_Dehli in enumerate(\n",
    "        tqdm.tqdm(\n",
    "            train_loader_Dehli,\n",
    "            desc=\"Training\",\n",
    "            bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "        )\n",
    "    ):\n",
    "        # getdata_Dehli\n",
    "        samples, labels = data_Dehli\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        x = samples.permute(0, 2, 1)\n",
    "\n",
    "        # zero optimizer_Dehli\n",
    "        optimizer_Dehli.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model_Dehli(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss_Dehli = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss_Dehli.backward()\n",
    "        optimizer_Dehli.step()\n",
    "\n",
    "        # update running variables\n",
    "        running_loss_Dehli += loss_Dehli.item()\n",
    "\n",
    "    running_loss_Dehli /= len(train_loader_Dehli)\n",
    "    training_loss_Dehli.append(running_loss_Dehli)\n",
    "    print(\"Epoch {}/{} | Loss: {:.4f}\".format(epoch + 1, epochs, running_loss_Dehli))\n",
    "\n",
    "    scheduler_Dehli.step()\n",
    "\n",
    "    # save model_Dehli\n",
    "    # torch.save(\n",
    "    #     {\n",
    "    #         \"model_Dehli_state_dict\": model_Dehli.state_dict(),\n",
    "    #         \"optimizer_Dehli_state_dict\": optimizer_Dehli.state_dict(),\n",
    "    #         \"loss\": running_loss_Dehli,\n",
    "    #     },\n",
    "    #     f\"D:/AQI-Forecasting/train_model_Dehli/model_Dehli_bilstm/logs/checkpoints1/checkpoint_{epoch+1}.ckpt\",\n",
    "    # )\n",
    "    if best_loss_Dehli > running_loss_Dehli:\n",
    "        best_loss_Dehli = running_loss_Dehli\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_Dehli_state_dict\": model_Dehli.state_dict(),\n",
    "                \"optimizer_Dehli_state_dict\": optimizer_Dehli.state_dict(),\n",
    "                \"loss\": running_loss_Dehli,\n",
    "            },\n",
    "            \"/kaggle/working/best_loss_Dehli_checkpoint.ckpt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "training_loss_Dehli = np.array(training_loss_Dehli)\n",
    "plt.plot(training_loss_Dehli)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dehli_test = InceptionTime(8, 128)\n",
    "chetkpoint_Dehli = torch.load(\n",
    "    \"/kaggle/working/best_loss_Dehli_checkpoint.ckpt\"\n",
    ")\n",
    "model_Dehli_test.load_state_dict(chetkpoint_Dehli[\"model_Dehli_state_dict\"])\n",
    "model_Dehli_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_Dehli = 0.0\n",
    "y_true_Dehli = []\n",
    "y_pred_Dehli = []\n",
    "for i_Dehli, test_Data_Dehli in enumerate(\n",
    "    tqdm.tqdm(\n",
    "        test_loader_Dehli, desc=\"Testing\", bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\"\n",
    "    )\n",
    "):\n",
    "    test_sample, test_labels = test_Data_Dehli\n",
    "    x = test_sample.permute(0, 2, 1)\n",
    "    # print(x.shape)\n",
    "    # print(test_sample.shape)\n",
    "    # print(test_labels.shape)\n",
    "    outputs1_Dehli = model_Dehli_test(x)\n",
    "    # print(outputs1_Dehli.shape)\n",
    "\n",
    "    loss_Dehli = criterion(outputs1_Dehli, test_labels)\n",
    "    running_loss_Dehli += loss_Dehli.item()\n",
    "\n",
    "    # Collect true and predicted values\n",
    "    y_true_Dehli.extend(test_labels.numpy().ravel())\n",
    "    y_pred_Dehli.extend(outputs1_Dehli.detach().numpy().ravel())\n",
    "# Calculate average loss_Dehli\n",
    "running_loss_Dehli /= len(test_loader_Dehli)\n",
    "print(f\"Test loss_Dehli: {running_loss_Dehli:.4f}\")\n",
    "\n",
    "# Calculate additional metrics for regression\n",
    "y_true_Dehli = np.array(y_true_Dehli)\n",
    "y_pred_Dehli = np.array(y_pred_Dehli)\n",
    "print(y_true_Dehli.shape)\n",
    "print(y_pred_Dehli.shape)\n",
    "print(y_true_Dehli[0])\n",
    "mse_Dehli = mean_squared_error(y_true_Dehli, y_pred_Dehli)\n",
    "mae_Dehli = mean_absolute_error(y_true_Dehli, y_pred_Dehli)\n",
    "r2_Dehli = r2_score(y_true_Dehli, y_pred_Dehli)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_Dehli:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_Dehli:.4f}\")\n",
    "print(f\"R^2 Score: {r2_Dehli:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_Dehli = np.array(y_true_Dehli)\n",
    "y_pred_Dehli = np.array(y_pred_Dehli)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị thực tế\n",
    "plt.plot(y_true_Dehli, color=\"blue\", label=\"Actual AQI\")\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị dự đoán\n",
    "plt.plot(y_pred_Dehli, color=\"green\", label=\"Predicted AQI\")\n",
    "\n",
    "# Đặt tiêu đề và nhãn cho đồ thị\n",
    "plt.title(\"AQI Prediction (Multivariate)\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"AQI\")\n",
    "\n",
    "# Hiển thị chú thích\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "best_loss_Bengaluru = float(\"inf\")\n",
    "training_loss_Bengaluru = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss_Bengaluru = 0.0\n",
    "    for i_Bengaluru, data_Bengaluru in enumerate(\n",
    "        tqdm.tqdm(\n",
    "            train_loader_Bengaluru,\n",
    "            desc=\"Training\",\n",
    "            bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "        )\n",
    "    ):\n",
    "        # getdata_Bengaluru\n",
    "        samples, labels = data_Bengaluru\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        x = samples.permute(0, 2, 1)\n",
    "\n",
    "        # zero optimizer_Bengaluru\n",
    "        optimizer_Bengaluru.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model_Bengaluru(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss_Bengaluru = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss_Bengaluru.backward()\n",
    "        optimizer_Bengaluru.step()\n",
    "\n",
    "        # update running variables\n",
    "        running_loss_Bengaluru += loss_Bengaluru.item()\n",
    "\n",
    "    running_loss_Bengaluru /= len(train_loader_Bengaluru)\n",
    "    training_loss_Bengaluru.append(running_loss_Bengaluru)\n",
    "    print(\n",
    "        \"Epoch {}/{} | Loss: {:.4f}\".format(epoch + 1, epochs, running_loss_Bengaluru)\n",
    "    )\n",
    "\n",
    "    scheduler_Bengaluru.step()\n",
    "\n",
    "    # save model_Bengaluru\n",
    "    # torch.save(\n",
    "    #     {\n",
    "    #         \"model_Bengaluru_state_dict\": model_Bengaluru.state_dict(),\n",
    "    #         \"optimizer_Bengaluru_state_dict\": optimizer_Bengaluru.state_dict(),\n",
    "    #         \"loss\": running_loss_Bengaluru,\n",
    "    #     },\n",
    "    #     f\"D:/AQI-Forecasting/train_model_Bengaluru/model_Bengaluru_bilstm/logs/checkpoints1/checkpoint_{epoch+1}.ckpt\",\n",
    "    # )\n",
    "    if best_loss_Bengaluru > running_loss_Bengaluru:\n",
    "        best_loss_Bengaluru = running_loss_Bengaluru\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_Bengaluru_state_dict\": model_Bengaluru.state_dict(),\n",
    "                \"optimizer_Bengaluru_state_dict\": optimizer_Bengaluru.state_dict(),\n",
    "                \"loss\": running_loss_Bengaluru,\n",
    "            },\n",
    "            \"/kaggle/working/best_loss_Bengaluru_checkpoint.ckpt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "training_loss_Bengaluru = np.array(training_loss_Bengaluru)\n",
    "plt.plot(training_loss_Bengaluru)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Bengaluru_test = InceptionTime(8, 128)\n",
    "chetkpoint_Bengaluru = torch.load(\"/kaggle/working/best_loss_Bengaluru_checkpoint.ckpt\")\n",
    "model_Bengaluru_test.load_state_dict(chetkpoint_Bengaluru[\"model_Bengaluru_state_dict\"])\n",
    "model_Bengaluru_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_Bengaluru = 0.0\n",
    "y_true_Bengaluru = []\n",
    "y_pred_Bengaluru = []\n",
    "for i_Bengaluru, test_Data_Bengaluru in enumerate(\n",
    "    tqdm.tqdm(\n",
    "        test_loader_Bengaluru,\n",
    "        desc=\"Testing\",\n",
    "        bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "    )\n",
    "):\n",
    "    test_sample1, test_labels1 = test_Data_Bengaluru\n",
    "    x = test_sample1.permute(0, 2, 1)\n",
    "    # print(x.shape)\n",
    "    # print(test_sample.shape)\n",
    "    # print(test_labels.shape)\n",
    "    outputs1_Bengaluru = model_Bengaluru_test(x)\n",
    "    # print(outputs1_Bengaluru.shape)\n",
    "\n",
    "    loss_Bengaluru = criterion(outputs1_Bengaluru, test_labels1)\n",
    "    running_loss_Bengaluru += loss_Bengaluru.item()\n",
    "\n",
    "    # Collect true and predicted values\n",
    "    y_true_Bengaluru.extend(test_labels1.numpy().ravel())\n",
    "    y_pred_Bengaluru.extend(outputs1_Bengaluru.detach().numpy().ravel())\n",
    "# Calculate average loss_Bengaluru\n",
    "running_loss_Bengaluru /= len(test_loader_Bengaluru)\n",
    "print(f\"Test loss_Bengaluru: {running_loss_Bengaluru:.4f}\")\n",
    "\n",
    "# Calculate additional metrics for regression\n",
    "y_true_Bengaluru = np.array(y_true_Bengaluru)\n",
    "y_pred_Bengaluru = np.array(y_pred_Bengaluru)\n",
    "print(y_true_Bengaluru.shape)\n",
    "print(y_pred_Bengaluru.shape)\n",
    "print(y_true_Bengaluru[0])\n",
    "mse_Bengaluru = mean_squared_error(y_true_Bengaluru, y_pred_Bengaluru)\n",
    "mae_Bengaluru = mean_absolute_error(y_true_Bengaluru, y_pred_Bengaluru)\n",
    "r2_Bengaluru = r2_score(y_true_Bengaluru, y_pred_Bengaluru)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_Bengaluru:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_Bengaluru:.4f}\")\n",
    "print(f\"R^2 Score: {r2_Bengaluru:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_Bengaluru = np.array(y_true_Bengaluru)\n",
    "y_pred_Bengaluru = np.array(y_pred_Bengaluru)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị thực tế\n",
    "plt.plot(y_true_Bengaluru, color=\"blue\", label=\"Actual AQI\")\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị dự đoán\n",
    "plt.plot(y_pred_Bengaluru, color=\"green\", label=\"Predicted AQI\")\n",
    "\n",
    "# Đặt tiêu đề và nhãn cho đồ thị\n",
    "plt.title(\"AQI Prediction (Multivariate)\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"AQI\")\n",
    "\n",
    "# Hiển thị chú thích\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "best_loss_Hyderabad = float(\"inf\")\n",
    "training_loss_Hyderabad = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss_Hyderabad = 0.0\n",
    "    for i_Hyderabad, data_Hyderabad in enumerate(\n",
    "        tqdm.tqdm(\n",
    "            train_loader_Hyderabad,\n",
    "            desc=\"Training\",\n",
    "            bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "        )\n",
    "    ):\n",
    "        # getdata_Hyderabad\n",
    "        samples, labels = data_Hyderabad\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        x = samples.permute(0, 2, 1)\n",
    "\n",
    "        # zero optimizer_Hyderabad\n",
    "        optimizer_Hyderabad.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model_Hyderabad(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss_Hyderabad = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss_Hyderabad.backward()\n",
    "        optimizer_Hyderabad.step()\n",
    "\n",
    "        # update running variables\n",
    "        running_loss_Hyderabad += loss_Hyderabad.item()\n",
    "\n",
    "    running_loss_Hyderabad /= len(train_loader_Hyderabad)\n",
    "    training_loss_Hyderabad.append(running_loss_Hyderabad)\n",
    "    print(\n",
    "        \"Epoch {}/{} | Loss: {:.4f}\".format(epoch + 1, epochs, running_loss_Hyderabad)\n",
    "    )\n",
    "\n",
    "    scheduler_Hyderabad.step()\n",
    "\n",
    "    # save model_Hyderabad\n",
    "    # torch.save(\n",
    "    #     {\n",
    "    #         \"model_Hyderabad_state_dict\": model_Hyderabad.state_dict(),\n",
    "    #         \"optimizer_Hyderabad_state_dict\": optimizer_Hyderabad.state_dict(),\n",
    "    #         \"loss\": running_loss_Hyderabad,\n",
    "    #     },\n",
    "    #     f\"D:/AQI-Forecasting/train_model_Hyderabad/model_Hyderabad_bilstm/logs/checkpoints1/checkpoint_{epoch+1}.ckpt\",\n",
    "    # )\n",
    "    if best_loss_Hyderabad > running_loss_Hyderabad:\n",
    "        best_loss_Hyderabad = running_loss_Hyderabad\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_Hyderabad_state_dict\": model_Hyderabad.state_dict(),\n",
    "                \"optimizer_Hyderabad_state_dict\": optimizer_Hyderabad.state_dict(),\n",
    "                \"loss\": running_loss_Hyderabad,\n",
    "            },\n",
    "            \"/kaggle/working/best_loss_Hyderabad_checkpoint.ckpt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "training_loss_Hyderabad = np.array(training_loss_Hyderabad)\n",
    "plt.plot(training_loss_Hyderabad)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Hyderabad_test = InceptionTime(8, 128)\n",
    "chetkpoint_Hyderabad = torch.load(\"/kaggle/working/best_loss_Hyderabad_checkpoint.ckpt\")\n",
    "model_Hyderabad_test.load_state_dict(chetkpoint_Hyderabad[\"model_Hyderabad_state_dict\"])\n",
    "model_Hyderabad_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_Hyderabad = 0.0\n",
    "y_true_Hyderabad = []\n",
    "y_pred_Hyderabad = []\n",
    "for i_Hyderabad, test_data_Hyderabad in enumerate(\n",
    "    tqdm.tqdm(\n",
    "        test_loader_Hyderabad,\n",
    "        desc=\"Testing\",\n",
    "        bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "    )\n",
    "):\n",
    "    test_sample2, test_labels2 = test_data_Hyderabad\n",
    "    x = test_sample2.permute(0, 2, 1)\n",
    "    # print(x.shape)\n",
    "    # print(test_sample.shape)\n",
    "    # print(test_labels.shape)\n",
    "    outputs1_Hyderabad = model_Hyderabad_test(x)\n",
    "    # print(outputs1_Hyderabad.shape)\n",
    "\n",
    "    loss_Hyderabad = criterion(outputs1_Hyderabad, test_labels2)\n",
    "    running_loss_Hyderabad += loss_Hyderabad.item()\n",
    "\n",
    "    # Collect true and predicted values\n",
    "    y_true_Hyderabad.extend(test_labels2.numpy().ravel())\n",
    "    y_pred_Hyderabad.extend(outputs1_Hyderabad.detach().numpy().ravel())\n",
    "# Calculate average loss_Hyderabad\n",
    "running_loss_Hyderabad /= len(test_loader_Hyderabad)\n",
    "print(f\"Test loss_Hyderabad: {running_loss_Hyderabad:.4f}\")\n",
    "\n",
    "# Calculate additional metrics for regression\n",
    "y_true_Hyderabad = np.array(y_true_Hyderabad)\n",
    "y_pred_Hyderabad = np.array(y_pred_Hyderabad)\n",
    "print(y_true_Hyderabad.shape)\n",
    "print(y_pred_Hyderabad.shape)\n",
    "print(y_true_Hyderabad[0])\n",
    "mse_Hyderabad = mean_squared_error(y_true_Hyderabad, y_pred_Hyderabad)\n",
    "mae_Hyderabad = mean_absolute_error(y_true_Hyderabad, y_pred_Hyderabad)\n",
    "r2_Hyderabad = r2_score(y_true_Hyderabad, y_pred_Hyderabad)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_Hyderabad:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_Hyderabad:.4f}\")\n",
    "print(f\"R^2 Score: {r2_Hyderabad:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_Hyderabad = np.array(y_true_Hyderabad)\n",
    "y_pred_Hyderabad = np.array(y_pred_Hyderabad)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị thực tế\n",
    "plt.plot(y_true_Hyderabad, color=\"blue\", label=\"Actual AQI\")\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị dự đoán\n",
    "plt.plot(y_pred_Hyderabad, color=\"green\", label=\"Predicted AQI\")\n",
    "\n",
    "# Đặt tiêu đề và nhãn cho đồ thị\n",
    "plt.title(\"AQI Prediction (Multivariate)\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"AQI\")\n",
    "\n",
    "# Hiển thị chú thích\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "best_loss_Taiwan = float(\"inf\")\n",
    "training_loss_Taiwan = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss_Taiwan = 0.0\n",
    "    for i_Taiwan, data_Taiwan in enumerate(\n",
    "        tqdm.tqdm(\n",
    "            train_loader_Taiwan,\n",
    "            desc=\"Training\",\n",
    "            bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "        )\n",
    "    ):\n",
    "        # getdata_Taiwan\n",
    "        samples, labels = data_Taiwan\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        x = samples.permute(0, 2, 1)\n",
    "\n",
    "        # zero optimizer_Taiwan\n",
    "        optimizer_Taiwan.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model_Taiwan(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss_Taiwan = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss_Taiwan.backward()\n",
    "        optimizer_Taiwan.step()\n",
    "\n",
    "        # update running variables\n",
    "        running_loss_Taiwan += loss_Taiwan.item()\n",
    "\n",
    "    running_loss_Taiwan /= len(train_loader_Taiwan)\n",
    "    training_loss_Taiwan.append(running_loss_Taiwan)\n",
    "    print(\"Epoch {}/{} | Loss: {:.4f}\".format(epoch + 1, epochs, running_loss_Taiwan))\n",
    "\n",
    "    scheduler_Taiwan.step()\n",
    "\n",
    "    # save model_Taiwan\n",
    "    # torch.save(\n",
    "    #     {\n",
    "    #         \"model_Taiwan_state_dict\": model_Taiwan.state_dict(),\n",
    "    #         \"optimizer_Taiwan_state_dict\": optimizer_Taiwan.state_dict(),\n",
    "    #         \"loss\": running_loss_Taiwan,\n",
    "    #     },\n",
    "    #     f\"D:/AQI-Forecasting/train_model_Taiwan/model_Taiwan_bilstm/logs/checkpoints1/checkpoint_{epoch+1}.ckpt\",\n",
    "    # )\n",
    "    if best_loss_Taiwan > running_loss_Taiwan:\n",
    "        best_loss_Taiwan = running_loss_Taiwan\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_Taiwan_state_dict\": model_Taiwan.state_dict(),\n",
    "                \"optimizer_Taiwan_state_dict\": optimizer_Taiwan.state_dict(),\n",
    "                \"loss\": running_loss_Taiwan,\n",
    "            },\n",
    "            \"/kaggle/working/best_loss_Taiwan_checkpoint.ckpt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "training_loss_Taiwan = np.array(training_loss_Taiwan)\n",
    "plt.plot(training_loss_Taiwan)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Taiwan_test = InceptionTime(8, 128)\n",
    "chetkpoint_Taiwan = torch.load(\"/kaggle/working/best_loss_Taiwan_checkpoint.ckpt\")\n",
    "model_Taiwan_test.load_state_dict(chetkpoint_Taiwan[\"model_Taiwan_state_dict\"])\n",
    "model_Taiwan_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc_Taiwan = 0.0\n",
    "y_true_Taiwan = []\n",
    "y_pred_Taiwan = []\n",
    "for i_Taiwan, test_data_Taiwan in enumerate(\n",
    "    tqdm.tqdm(\n",
    "        test_loader_Taiwan,\n",
    "        desc=\"Testing\",\n",
    "        bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    "    )\n",
    "):\n",
    "    test_sample3, test_labels3 = test_data_Taiwan\n",
    "    x = test_sample3.rmute(0, 2, 1)\n",
    "    # print(x.shape)\n",
    "    # print(test_sample.shape)\n",
    "    # print(test_labels.shape)\n",
    "    outputs1_Taiwan = model_Taiwan_test(x)\n",
    "    # print(outputs1_Taiwan.shape)\n",
    "\n",
    "    loss_Taiwan = criterion(outputs1_Taiwan, test_labels3)\n",
    "    running_loss_Taiwan += loss_Taiwan.item()\n",
    "\n",
    "    # Collect true and predicted values\n",
    "    y_true_Taiwan.extend(test_labels3.numpy().ravel())\n",
    "    y_pred_Taiwan.extend(outputs1_Taiwan.detach().numpy().ravel())\n",
    "# Calculate average loss_Taiwan\n",
    "running_loss_Taiwan /= len(test_loader_Taiwan)\n",
    "print(f\"Test loss_Taiwan: {running_loss_Taiwan:.4f}\")\n",
    "\n",
    "# Calculate additional metrics for regression\n",
    "y_true_Taiwan = np.array(y_true_Taiwan)\n",
    "y_pred_Taiwan = np.array(y_pred_Taiwan)\n",
    "print(y_true_Taiwan.shape)\n",
    "print(y_pred_Taiwan.shape)\n",
    "print(y_true_Taiwan[0])\n",
    "mse_Taiwan = mean_squared_error(y_true_Taiwan, y_pred_Taiwan)\n",
    "mae_Taiwan = mean_absolute_error(y_true_Taiwan, y_pred_Taiwan)\n",
    "r2_Taiwan = r2_score(y_true_Taiwan, y_pred_Taiwan)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_Taiwan:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_Taiwan:.4f}\")\n",
    "print(f\"R^2 Score: {r2_Taiwan:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_Taiwan = np.array(y_true_Taiwan)\n",
    "y_pred_Taiwan = np.array(y_pred_Taiwan)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị thực tế\n",
    "plt.plot(y_true_Taiwan, color=\"blue\", label=\"Actual AQI\")\n",
    "\n",
    "# Vẽ đường biểu diễn giá trị dự đoán\n",
    "plt.plot(y_pred_Taiwan, color=\"green\", label=\"Predicted AQI\")\n",
    "\n",
    "# Đặt tiêu đề và nhãn cho đồ thị\n",
    "plt.title(\"AQI Prediction (Multivariate)\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"AQI\")\n",
    "\n",
    "# Hiển thị chú thích\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
